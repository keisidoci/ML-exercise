{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/keisidoci/ML-exercise/blob/main/Exercise1_ML.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iAMBHAaDL1W5"
      },
      "source": [
        "# Exercise 1 Machine learning: From Lines to Layers\n",
        "\n",
        "**A Journey from Linear Models to Neural Networks**\n",
        "\n",
        "---\n",
        "\n",
        "## Learning Goals\n",
        "\n",
        "By the end of this practical session, you will:\n",
        "\n",
        "1. Understand the difference between **Regression** and **Classification**\n",
        "2. Implement and train **Linear Regression** for predicting continuous values\n",
        "3. Implement and train three classification models:\n",
        "   - **Perceptron** (the original neural network!)\n",
        "   - **Logistic Regression** (a probabilistic classifier)\n",
        "   - **Multi-Layer Perceptron (MLP)** (your first deep neural network!)\n",
        "4. Visualize the **decision boundaries** of different models\n",
        "5. Discover **why** and **when** an MLP is necessary by comparing model performance on simple and complex datasets\n",
        "6. Master the **train/test split** methodology for proper model evaluation\n",
        "7. Experiment with **hyperparameters** to understand their impact on performance\n",
        "8. Apply models to **real-world data** with proper preprocessing\n",
        "9. Evaluate models using **advanced metrics**: confusion matrix, precision, recall, and F1-score\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aTRBt3XGL1W5"
      },
      "source": [
        "## Section 0: Introduction & Setup\n",
        "\n",
        "Let's start by importing all the necessary libraries. Make sure you have `scikit-learn`, `numpy`, and `matplotlib` installed.\n",
        "\n",
        "If not, install them using:\n",
        "\n",
        "```bash\n",
        "pip install scikit-learn numpy matplotlib pandas\n",
        "```\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9hK0kbE2L1W5"
      },
      "outputs": [],
      "source": [
        "!pip install scikit-learn numpy matplotlib pandas"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vKWpnXAzL1W6"
      },
      "outputs": [],
      "source": [
        "# Import necessary libraries\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from matplotlib.colors import ListedColormap\n",
        "\n",
        "# Dataset generation\n",
        "from sklearn.datasets import make_regression, make_moons, make_circles, load_iris\n",
        "\n",
        "# Models\n",
        "from sklearn.linear_model import LinearRegression, Perceptron, LogisticRegression\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "\n",
        "# Evaluation metrics\n",
        "from sklearn.metrics import mean_squared_error, accuracy_score\n",
        "\n",
        "# Data splitting\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Set random seed for reproducibility\n",
        "np.random.seed(42)\n",
        "\n",
        "# Configure matplotlib for better plots\n",
        "plt.style.use(\"default\")\n",
        "plt.rcParams[\"figure.figsize\"] = (10, 6)\n",
        "plt.rcParams[\"font.size\"] = 11\n",
        "\n",
        "print(\"âœ“ All libraries imported successfully!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zp5pXgnHL1W6"
      },
      "source": [
        "### Helper Function: Plotting Decision Boundaries\n",
        "\n",
        "This function is provided to help you visualize how different models make decisions.\n",
        "\n",
        "**You don't need to understand all the details**, but the key idea is:\n",
        "\n",
        "- It creates a grid of points covering the entire space\n",
        "- It asks the model to predict the class for each point\n",
        "- It colors the regions based on the predictions\n",
        "- This shows us the **decision boundary** (the line or curve separating different classes)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Z7JSkqqQL1W6"
      },
      "outputs": [],
      "source": [
        "def plot_decision_boundary(X, y, model, title=\"Decision Boundary\"):\n",
        "    \"\"\"\n",
        "    Plot the decision boundary of a classification model.\n",
        "\n",
        "    Parameters:\n",
        "    -----------\n",
        "    X : array-like, shape (n_samples, 2)\n",
        "        Training data (only 2D data is supported for visualization)\n",
        "    y : array-like, shape (n_samples,)\n",
        "        Target labels\n",
        "    model : scikit-learn classifier\n",
        "        Trained classification model\n",
        "    title : str\n",
        "        Title for the plot\n",
        "    \"\"\"\n",
        "    # Set up the mesh grid\n",
        "    h = 0.02  # Step size in the mesh\n",
        "    x_min, x_max = X[:, 0].min() - 1, X[:, 0].max() + 1\n",
        "    y_min, y_max = X[:, 1].min() - 1, X[:, 1].max() + 1\n",
        "    xx, yy = np.meshgrid(np.arange(x_min, x_max, h), np.arange(y_min, y_max, h))\n",
        "\n",
        "    # Predict for each point in the mesh\n",
        "    Z = model.predict(np.c_[xx.ravel(), yy.ravel()])\n",
        "    Z = Z.reshape(xx.shape)\n",
        "\n",
        "    # Create color maps\n",
        "    cmap_light = ListedColormap([\"#FFAAAA\", \"#AAAAFF\", \"#AAFFAA\"])\n",
        "    cmap_bold = ListedColormap([\"#FF0000\", \"#0000FF\", \"#00FF00\"])\n",
        "\n",
        "    # Plot the decision boundary\n",
        "    plt.figure(figsize=(10, 6))\n",
        "    plt.contourf(xx, yy, Z, alpha=0.4, cmap=cmap_light)\n",
        "\n",
        "    # Plot the training points\n",
        "    scatter = plt.scatter(\n",
        "        X[:, 0], X[:, 1], c=y, cmap=cmap_bold, edgecolor=\"black\", s=50, alpha=0.7\n",
        "    )\n",
        "\n",
        "    plt.xlabel(\"Feature 1\")\n",
        "    plt.ylabel(\"Feature 2\")\n",
        "    plt.title(title)\n",
        "    plt.colorbar(scatter)\n",
        "    plt.grid(True, alpha=0.3)\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "print(\"âœ“ Helper function defined!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jUFqdXR8L1W6"
      },
      "source": [
        "---\n",
        "\n",
        "# Part 1: Predicting a Value (Regression)\n",
        "\n",
        "## What is Regression?\n",
        "\n",
        "**Regression** is the task of predicting a **continuous number** based on input features.\n",
        "\n",
        "**Examples:**\n",
        "- Predicting house prices based on size, location, number of rooms\n",
        "- Predicting temperature based on time of day, season, location\n",
        "- Predicting a student's exam score based on study hours\n",
        "\n",
        "The simplest regression model is **Linear Regression**, which tries to find the best straight line (or hyperplane in higher dimensions) that fits the data.\n",
        "\n",
        "**Formula:** $y = mx + c$ (in 1D) or $y = \\theta^T x$ (in general)\n",
        "\n",
        "---\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I-zWlyisL1W6"
      },
      "source": [
        "## 1.1 The Dataset\n",
        "\n",
        "Let's create a simple 1D synthetic dataset. We'll generate 100 data points with some random noise.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nKgDZgViL1W6"
      },
      "outputs": [],
      "source": [
        "# Generate synthetic regression data\n",
        "X_reg, y_reg = make_regression(n_samples=100, n_features=1, noise=10, random_state=42)\n",
        "\n",
        "# Visualize the data\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.scatter(X_reg, y_reg, alpha=0.7, edgecolor=\"black\")\n",
        "plt.xlabel(\"Feature X\")\n",
        "plt.ylabel(\"Target y\")\n",
        "plt.title(\"Regression Dataset: Can you imagine a line that fits this data?\")\n",
        "plt.grid(True, alpha=0.3)\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "print(f\"Dataset shape: {X_reg.shape}\")\n",
        "print(f\"Number of samples: {X_reg.shape[0]}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tI8MV4UaL1W6"
      },
      "source": [
        "### Question for Reflection\n",
        "\n",
        "Looking at the scatter plot above:\n",
        "\n",
        "- Can you mentally draw a straight line that would fit most of these points?\n",
        "- What would be the approximate slope of that line?\n",
        "\n",
        "---\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dEWpK17oL1W6"
      },
      "source": [
        "## 1.2 The Model: Linear Regression\n",
        "\n",
        "**Linear Regression** finds the best possible straight line (in 2D) or hyperplane (in higher dimensions) that fits the data.\n",
        "\n",
        "**How it works:**\n",
        "\n",
        "1. It tries to minimize the **Mean Squared Error (MSE)** between predictions and actual values\n",
        "2. MSE = $\\frac{1}{n} \\sum_{i=1}^{n} (y_i - \\hat{y}_i)^2$\n",
        "3. The model learns the parameters $\\theta$ (slope and intercept) that minimize this error\n",
        "\n",
        "---\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "evJYKeG_L1W6"
      },
      "source": [
        "## 1.3 Your Turn: Train the Linear Regression Model\n",
        "\n",
        "**TODO:** Complete the code below to train the Linear Regression model.\n",
        "\n",
        "**Hints:**\n",
        "\n",
        "- Use the `.fit()` method to train the model\n",
        "- Use the `.predict()` method to get predictions\n",
        "- The training data is `X_reg` (features) and `y_reg` (targets)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EG_yWuVnL1W6"
      },
      "outputs": [],
      "source": [
        "# --- TODO: Student completes this section ---\n",
        "# Initialize the Linear Regression model\n",
        "# YOUR CODE HERE:  model_lr = ...\n",
        "\n",
        "# Train the model on our data X_reg and y_reg\n",
        "# YOUR CODE HERE: model_lr.fit(...)\n",
        "\n",
        "# Get the model's predictions\n",
        "# YOUR CODE HERE: y_pred_lr = model_lr.predict(...)\n",
        "# --- End of TODO ---\n",
        "\n",
        "# Print the learned parameters\n",
        "print(f\"Model trained successfully!\")\n",
        "print(f\"Learned Slope (m): {model_lr.coef_[0]:.4f}\")\n",
        "print(f\"Learned Intercept (c): {model_lr.intercept_:.4f}\")\n",
        "print(f\"\\nModel equation: y = {model_lr.coef_[0]:.4f} * x + {model_lr.intercept_:.4f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pyTayeBJL1W6"
      },
      "source": [
        "## 1.4 Evaluation: How Good is Our Model?\n",
        "\n",
        "Let's visualize the model's predictions and calculate the error.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "x56KDu_fL1W6"
      },
      "outputs": [],
      "source": [
        "# Visualize the original data and the model's prediction line\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.scatter(X_reg, y_reg, alpha=0.7, edgecolor=\"black\", label=\"Actual data\")\n",
        "plt.plot(X_reg, y_pred_lr, color=\"red\", linewidth=2, label=\"Linear Regression fit\")\n",
        "plt.xlabel(\"Feature X\")\n",
        "plt.ylabel(\"Target y\")\n",
        "plt.title(\"Linear Regression: Predicted Line vs Actual Data\")\n",
        "plt.legend()\n",
        "plt.grid(True, alpha=0.3)\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# Calculate the Mean Squared Error\n",
        "mse = mean_squared_error(y_reg, y_pred_lr)\n",
        "print(f\"Mean Squared Error (MSE): {mse:.2f}\")\n",
        "print(f\"\\n The MSE tells us, on average, how 'wrong' our predictions are.\")\n",
        "print(f\"   Lower MSE = Better model!\")\n",
        "print(f\"\\n But wait! We have a problem...\")\n",
        "print(f\"   We're testing on the SAME data we trained on!\")\n",
        "print(f\"   This doesn't tell us how well our model generalizes to NEW data.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MsGt2B-VL1W6"
      },
      "source": [
        "## 1.5 The Golden Rule: Train/Test Split\n",
        "\n",
        "### Why Do We Need Train/Test Split?\n",
        "\n",
        "Imagine you're preparing for an exam:\n",
        "\n",
        "- **Training data**: Practice problems you study from\n",
        "- **Test data**: The actual exam questions (which you haven't seen!)\n",
        "\n",
        "If the exam only asks the exact same questions you practiced, does that really test your understanding? **No!**\n",
        "\n",
        "**The same applies to machine learning:**\n",
        "\n",
        "- **Training set**: Data the model learns from\n",
        "- **Test set**: NEW data the model has never seen (to evaluate true performance)\n",
        "\n",
        "**Key concept:** A good model should **generalize** well to new, unseen data!\n",
        "\n",
        "---\n",
        "\n",
        "### The Dangers of Not Splitting\n",
        "\n",
        "If we train and test on the same data, we might:\n",
        "\n",
        "1. **Overestimate** performance (the model \"memorized\" the training data)\n",
        "2. Miss **overfitting** (model performs well on training data but poorly on new data)\n",
        "3. Make bad decisions about which model to deploy\n",
        "\n",
        "---\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5RVwkpG1L1W6"
      },
      "source": [
        "### TODO: Implement Train/Test Split\n",
        "\n",
        "Your task: Split the regression data and evaluate properly!\n",
        "\n",
        "**Steps:**\n",
        "\n",
        "1. Use `train_test_split()` to split `X_reg` and `y_reg` into training and test sets\n",
        "2. Use **80% for training** and **20% for testing** (test_size=0.2)\n",
        "3. Train a NEW Linear Regression model on the training set\n",
        "4. Evaluate on BOTH training and test sets\n",
        "5. Compare the two MSE values\n",
        "\n",
        "**Hints:**\n",
        "\n",
        "- `train_test_split(X, y, test_size=0.2, random_state=42)`\n",
        "- Returns: `X_train, X_test, y_train, y_test`\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gqIFN0GyL1W6"
      },
      "outputs": [],
      "source": [
        "# --- TODO: Student completes train/test split ---\n",
        "# Step 1: Split the data\n",
        "# YOUR CODE HERE: X_train, X_test, y_train, y_test = train_test_split(...)\n",
        "\n",
        "# Step 2: Train a new model on training data only\n",
        "# YOUR CODE HERE: model_lr_split = ...\n",
        "# YOUR CODE HERE: model_lr_split.fit(...)\n",
        "\n",
        "# Step 3: Make predictions on BOTH sets\n",
        "# YOUR CODE HERE: y_train_pred = model_lr_split.predict(...)\n",
        "# YOUR CODE HERE: y_test_pred = model_lr_split.predict(...)\n",
        "\n",
        "# Step 4: Calculate MSE for both sets\n",
        "# YOUR CODE HERE: mse_train = mean_squared_error(...)\n",
        "# YOUR CODE HERE: mse_test = mean_squared_error(...)\n",
        "# --- End of TODO ---\n",
        "\n",
        "# Print results\n",
        "print(\"=\" * 60)\n",
        "print(\"TRAIN/TEST SPLIT EVALUATION\")\n",
        "print(\"=\" * 60)\n",
        "print(f\"Training Set MSE:   {mse_train:.2f}\")\n",
        "print(f\"Test Set MSE:       {mse_test:.2f}\")\n",
        "print(f\"Difference:         {abs(mse_test - mse_train):.2f}\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "if abs(mse_test - mse_train) < 20:\n",
        "    print(\"\\nGood! The model generalizes well to unseen data.\")\n",
        "    print(\"   Training and test errors are similar.\")\n",
        "else:\n",
        "    print(\"\\nWarning: Large difference between train and test error!\")\n",
        "    print(\"   This might indicate overfitting or a problem with the split.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7ZMLgPsFL1W6"
      },
      "source": [
        "### Visualization: Training vs Test Data\n",
        "\n",
        "Let's visualize how our model performs on both sets!\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8znpe2rdL1W6"
      },
      "outputs": [],
      "source": [
        "# Visualize train and test split\n",
        "plt.figure(figsize=(12, 5))\n",
        "\n",
        "# Plot 1: Training data\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.scatter(\n",
        "    X_train, y_train, alpha=0.7, edgecolor=\"black\", label=\"Training data\", color=\"blue\"\n",
        ")\n",
        "plt.plot(X_train, y_train_pred, color=\"red\", linewidth=2, label=\"Model fit\")\n",
        "plt.xlabel(\"Feature X\")\n",
        "plt.ylabel(\"Target y\")\n",
        "plt.title(f\"Training Set (MSE: {mse_train:.2f})\")\n",
        "plt.legend()\n",
        "plt.grid(True, alpha=0.3)\n",
        "\n",
        "# Plot 2: Test data\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.scatter(\n",
        "    X_test, y_test, alpha=0.7, edgecolor=\"black\", label=\"Test data\", color=\"green\"\n",
        ")\n",
        "plt.plot(X_test, y_test_pred, color=\"red\", linewidth=2, label=\"Model prediction\")\n",
        "plt.xlabel(\"Feature X\")\n",
        "plt.ylabel(\"Target y\")\n",
        "plt.title(f\"Test Set (MSE: {mse_test:.2f})\")\n",
        "plt.legend()\n",
        "plt.grid(True, alpha=0.3)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "print(\"Notice: We train on the BLUE points, but test on the GREEN points!\")\n",
        "print(\"   This gives us a true measure of generalization.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q3Yj6Na7L1W6"
      },
      "source": [
        "### Key Takeaway: Linear Regression\n",
        "\n",
        "- **Linear Regression** is great for finding **linear trends** in data\n",
        "- It predicts **continuous values** (numbers)\n",
        "- It works by finding the best-fit line that minimizes the error\n",
        "- **Limitation:** It can only model **linear relationships** (straight lines)\n",
        "\n",
        "---\n",
        "\n",
        "**Next up:** What if we want to predict **categories** instead of numbers? That's where **Classification** comes in!\n",
        "\n",
        "---\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UAHPHuRmL1W6"
      },
      "source": [
        "# Part 2: Making a Choice (Classification)\n",
        "\n",
        "## What is Classification?\n",
        "\n",
        "**Classification** is the task of predicting a **category** or **class** based on input features.\n",
        "\n",
        "**Examples:**\n",
        "\n",
        "- Email: Spam or Not Spam?\n",
        "- Medical diagnosis: Disease or Healthy?\n",
        "- Image: Cat or Dog?\n",
        "- Flower species: Iris Setosa, Iris Versicolor, or Iris Virginica?\n",
        "\n",
        "In this section, we'll train three different classification models:\n",
        "\n",
        "1. **Perceptron** - The original neural network (1958!)\n",
        "2. **Logistic Regression** - A probabilistic linear classifier\n",
        "3. We'll save the best for last...\n",
        "\n",
        "---\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iim-66QNL1W7"
      },
      "source": [
        "## 2.1 The Dataset: Iris Flowers\n",
        "\n",
        "We'll use the famous **Iris dataset**. To keep things simple, we'll:\n",
        "\n",
        "- Use only the **first 2 features** (sepal length and sepal width)\n",
        "- Use only the **first 2 classes** (Setosa and Versicolor)\n",
        "\n",
        "This creates a **linearly separable** dataset - perfect for testing our linear models!\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Fpz23uQ7L1W7"
      },
      "outputs": [],
      "source": [
        "# Load the Iris dataset\n",
        "iris = load_iris()\n",
        "\n",
        "# Use only first 100 samples (classes 0 and 1) and first 2 features\n",
        "X_iris = iris.data[:100, :2]  # First 2 features: sepal length, sepal width\n",
        "y_iris = iris.target[:100]  # First 2 classes: Setosa (0) and Versicolor (1)\n",
        "\n",
        "# Visualize the data\n",
        "plt.figure(figsize=(10, 6))\n",
        "colors = [\"red\", \"blue\"]\n",
        "for class_value in [0, 1]:\n",
        "    mask = y_iris == class_value\n",
        "    plt.scatter(\n",
        "        X_iris[mask, 0],\n",
        "        X_iris[mask, 1],\n",
        "        c=colors[class_value],\n",
        "        label=iris.target_names[class_value],\n",
        "        alpha=0.7,\n",
        "        edgecolor=\"black\",\n",
        "        s=100,\n",
        "    )\n",
        "\n",
        "plt.xlabel(\"Sepal Length (cm)\")\n",
        "plt.ylabel(\"Sepal Width (cm)\")\n",
        "plt.title(\n",
        "    \"Iris Dataset: Can you draw a SINGLE straight line to separate the two classes?\"\n",
        ")\n",
        "plt.legend()\n",
        "plt.grid(True, alpha=0.3)\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "print(f\"Dataset shape: {X_iris.shape}\")\n",
        "print(f\"Class 0 (Setosa): {sum(y_iris == 0)} samples\")\n",
        "print(f\"Class 1 (Versicolor): {sum(y_iris == 1)} samples\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3wiXcXPJL1W7"
      },
      "source": [
        "### Question for Reflection\n",
        "\n",
        "Looking at the scatter plot above:\n",
        "\n",
        "- Can you mentally draw a **single straight line** to separate the red and blue points?\n",
        "- What would happen if you drew a vertical line at x â‰ˆ 5.5?\n",
        "\n",
        "**Answer:** Yes! This dataset is **linearly separable**. This means our linear models should work very well!\n",
        "\n",
        "---\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HsBpxo8CL1W7"
      },
      "source": [
        "## 2.2 Model A: The Perceptron\n",
        "\n",
        "### What is a Perceptron?\n",
        "\n",
        "The **Perceptron** is the original neural network, invented by Frank Rosenblatt in 1958!\n",
        "\n",
        "**How it works:**\n",
        "\n",
        "- It's a single \"neuron\" that finds a **straight line** (decision boundary) to separate classes\n",
        "- Formula: $\\hat{y} = \\text{step}(w^T x + b)$\n",
        "  - If $w^T x + b > 0$, predict class 1\n",
        "  - If $w^T x + b \\leq 0$, predict class 0\n",
        "- It's very simple but powerful for linearly separable data!\n",
        "\n",
        "**Limitation:** It only works if the data is linearly separable.\n",
        "\n",
        "---\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R-F0ZDVHL1W7"
      },
      "source": [
        "### TODO: Train the Perceptron\n",
        "\n",
        "Complete the code below to train the Perceptron model.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FmwkV9b9L1W7"
      },
      "outputs": [],
      "source": [
        "# --- TODO: Train the Perceptron ---\n",
        "# Initialize the Perceptron model\n",
        "# YOUR CODE HERE: model_pct = ...\n",
        "# YOUR CODE HERE: model_pct.fit(...)\n",
        "# --- End of TODO ---\n",
        "\n",
        "# Make predictions\n",
        "y_pred_pct = model_pct.predict(X_iris)\n",
        "\n",
        "# Calculate accuracy\n",
        "accuracy_pct = accuracy_score(y_iris, y_pred_pct)\n",
        "print(f\"Perceptron trained successfully!\")\n",
        "print(f\"Accuracy: {accuracy_pct * 100:.2f}%\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CrRBikX3L1W7"
      },
      "source": [
        "### Visualize the Perceptron's Decision Boundary\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pn_VMksGL1W7"
      },
      "outputs": [],
      "source": [
        "# Plot the decision boundary\n",
        "plot_decision_boundary(\n",
        "    X_iris,\n",
        "    y_iris,\n",
        "    model_pct,\n",
        "    title=f\"Perceptron Decision Boundary (Accuracy: {accuracy_pct * 100:.2f}%)\",\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M0ZeACRUL1W7"
      },
      "source": [
        "### Observation\n",
        "\n",
        "Notice how the Perceptron found a **straight line** to separate the two classes! The colored regions show which class the model would predict for any point in that area.\n",
        "\n",
        "---\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o8aUvvJ1L1W7"
      },
      "source": [
        "## 2.3 Model B: Logistic Regression\n",
        "\n",
        "### What is Logistic Regression?\n",
        "\n",
        "Despite its name, **Logistic Regression** is a **classification** model, not a regression model!\n",
        "\n",
        "**How it differs from Perceptron:**\n",
        "\n",
        "- Like the Perceptron, it finds a **linear** decision boundary\n",
        "- **Key difference:** It uses a **sigmoid function** to output **probabilities** (0 to 1)\n",
        "- Formula: $P(y=1|x) = \\sigma(w^T x + b) = \\frac{1}{1 + e^{-(w^T x + b)}}$\n",
        "\n",
        "**Advantages:**\n",
        "\n",
        "- Outputs probabilities, not just hard classifications\n",
        "- More stable training than Perceptron\n",
        "- Can be extended to multi-class problems\n",
        "\n",
        "---\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tRzf0LCgL1W7"
      },
      "source": [
        "### TODO: Train Logistic Regression\n",
        "\n",
        "Complete the code below to train the Logistic Regression model.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LzBESXzuL1W7"
      },
      "outputs": [],
      "source": [
        "# --- TODO: Train the Logistic Regression model ---\n",
        "# Initialize the Logistic Regression model\n",
        "# YOUR CODE HERE: model_logreg = ...\n",
        "# YOUR CODE HERE: model_logreg.fit(...)\n",
        "# YOUR CODE HERE:  y_pred_logreg = model_logreg.predict(...)\n",
        "# --- End of TODO ---\n",
        "# Calculate accuracy\n",
        "accuracy_logreg = accuracy_score(y_iris, y_pred_logreg)\n",
        "print(f\"âœ“ Logistic Regression trained successfully!\")\n",
        "print(f\"Accuracy: {accuracy_logreg * 100:.2f}%\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HzAOWmlgL1W7"
      },
      "source": [
        "### Visualize Logistic Regression's Decision Boundary\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WDOcRWU-L1W7"
      },
      "outputs": [],
      "source": [
        "# Plot the decision boundary\n",
        "plot_decision_boundary(\n",
        "    X_iris,\n",
        "    y_iris,\n",
        "    model_logreg,\n",
        "    title=f\"Logistic Regression Decision Boundary (Accuracy: {accuracy_logreg * 100:.2f}%)\",\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qfWvHW81L1W7"
      },
      "source": [
        "### Bonus: See the Probabilities!\n",
        "\n",
        "Unlike the Perceptron, Logistic Regression can tell us the **probability** of each prediction.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "z1e7heW-L1W7"
      },
      "outputs": [],
      "source": [
        "# Get probability predictions for the first 10 samples\n",
        "y_proba_logreg = model_logreg.predict_proba(X_iris[:10])\n",
        "\n",
        "print(\"First 10 samples - Predicted probabilities:\")\n",
        "print(\"Sample | P(Class 0) | P(Class 1) | Prediction\")\n",
        "print(\"-\" * 50)\n",
        "for i in range(10):\n",
        "    prob_0, prob_1 = y_proba_logreg[i]\n",
        "    prediction = \"Class 0\" if prob_0 > prob_1 else \"Class 1\"\n",
        "    print(f\"{i:6d} | {prob_0:10.4f} | {prob_1:10.4f} | {prediction}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bhumhQuSL1W7"
      },
      "source": [
        "## 2.4 Comparison: Perceptron vs Logistic Regression\n",
        "\n",
        "Let's compare the two models side by side.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iQq95La9L1XB"
      },
      "outputs": [],
      "source": [
        "# Print comparison\n",
        "print(\"=\" * 60)\n",
        "print(\"MODEL COMPARISON ON LINEARLY SEPARABLE DATA (Iris)\")\n",
        "print(\"=\" * 60)\n",
        "print(f\"Perceptron Accuracy:        {accuracy_pct * 100:.2f}%\")\n",
        "print(f\"Logistic Regression Accuracy: {accuracy_logreg * 100:.2f}%\")\n",
        "print(\"=\" * 60)\n",
        "print(\"\\nKey Insights:\")\n",
        "print(\"   â€¢ Both models achieve similar high accuracy (~100%)\")\n",
        "print(\"   â€¢ Why? Because the data is LINEARLY SEPARABLE\")\n",
        "print(\"   â€¢ Both models found a line that works!\")\n",
        "print(\"   â€¢ Main difference: Logistic Regression gives probabilities\")\n",
        "print(\"\\nBut what happens when data is NOT linearly separable?\")\n",
        "print(\"   Let's find out in Part 3...\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GAC3nv_RL1XC"
      },
      "source": [
        "---\n",
        "# Part 3: The Final Challenge (When Lines Fail)\n",
        "\n",
        "## The Problem with Linear Models\n",
        "\n",
        "So far, we've seen that linear models (Perceptron and Logistic Regression) work great when data is **linearly separable**.\n",
        "\n",
        "**But what happens when the data CANNOT be separated by a single straight line?**\n",
        "\n",
        "Let's find out!\n",
        "---\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NQ3IrugTL1XC"
      },
      "source": [
        "## 3.1 The \"Impossible\" Dataset: Moons\n",
        "\n",
        "Let's create a dataset where the two classes form two interleaving half-circles (\"moons\").\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AILOtj_GL1XC"
      },
      "outputs": [],
      "source": [
        "# Generate the moons dataset\n",
        "X_moons, y_moons = make_moons(n_samples=200, noise=0.1, random_state=42)\n",
        "\n",
        "# Visualize the data\n",
        "plt.figure(figsize=(10, 6))\n",
        "colors = [\"red\", \"blue\"]\n",
        "for class_value in [0, 1]:\n",
        "    mask = y_moons == class_value\n",
        "    plt.scatter(\n",
        "        X_moons[mask, 0],\n",
        "        X_moons[mask, 1],\n",
        "        c=colors[class_value],\n",
        "        label=f\"Class {class_value}\",\n",
        "        alpha=0.7,\n",
        "        edgecolor=\"black\",\n",
        "        s=50,\n",
        "    )\n",
        "\n",
        "plt.xlabel(\"Feature 1\")\n",
        "plt.ylabel(\"Feature 2\")\n",
        "plt.title(\"Moons Dataset: Can you separate these with ONE straight line? \")\n",
        "plt.legend()\n",
        "plt.grid(True, alpha=0.3)\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "print(f\"Dataset shape: {X_moons.shape}\")\n",
        "print(\n",
        "    f\"\\nðŸŽ¯ Challenge: Try to mentally draw a SINGLE straight line that separates red from blue.\"\n",
        ")\n",
        "print(f\"   Impossible, right? The data is NOT linearly separable!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7NvxSX7XL1XC"
      },
      "source": [
        "### Question for Reflection\n",
        "\n",
        "- Can you draw a **single straight line** to perfectly separate the red and blue points?\n",
        "- What kind of boundary would you need? (Hint: It would need to be curved!)\n",
        "\n",
        "---\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JaBr4tXfL1XC"
      },
      "source": [
        "## 3.2 Let's Watch Our Linear Models Struggle\n",
        "\n",
        "Let's see how the Perceptron and Logistic Regression perform on this challenging dataset.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Nio-wxGML1XC"
      },
      "outputs": [],
      "source": [
        "# Train Perceptron on moons data\n",
        "model_pct_moons = Perceptron(random_state=42, max_iter=1000)\n",
        "model_pct_moons.fit(X_moons, y_moons)\n",
        "y_pred_pct_moons = model_pct_moons.predict(X_moons)\n",
        "accuracy_pct_moons = accuracy_score(y_moons, y_pred_pct_moons)\n",
        "\n",
        "# Train Logistic Regression on moons data\n",
        "model_logreg_moons = LogisticRegression(random_state=42)\n",
        "model_logreg_moons.fit(X_moons, y_moons)\n",
        "y_pred_logreg_moons = model_logreg_moons.predict(X_moons)\n",
        "accuracy_logreg_moons = accuracy_score(y_moons, y_pred_logreg_moons)\n",
        "\n",
        "print(\"Results on Moons Dataset:\")\n",
        "print(f\"Perceptron Accuracy:        {accuracy_pct_moons * 100:.2f}%\")\n",
        "print(f\"Logistic Regression Accuracy: {accuracy_logreg_moons * 100:.2f}%\")\n",
        "print(\"\\nBoth models are struggling! Why? They're trying to draw a straight line,\")\n",
        "print(\"   but this problem needs a CURVED boundary!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UmH9cnYSL1XC"
      },
      "source": [
        "### Visualize the Failure\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9XRextwHL1XC"
      },
      "outputs": [],
      "source": [
        "# Plot Perceptron's attempt\n",
        "plot_decision_boundary(\n",
        "    X_moons,\n",
        "    y_moons,\n",
        "    model_pct_moons,\n",
        "    title=f\"Perceptron on Moons (Accuracy: {accuracy_pct_moons * 100:.2f}%) - FAILING!\",\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zdmuypY3L1XC"
      },
      "outputs": [],
      "source": [
        "# Plot Logistic Regression's attempt\n",
        "plot_decision_boundary(\n",
        "    X_moons,\n",
        "    y_moons,\n",
        "    model_logreg_moons,\n",
        "    title=f\"Logistic Regression on Moons (Accuracy: {accuracy_logreg_moons * 100:.2f}%) - FAILING!\",\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p_WZxpRPL1XC"
      },
      "source": [
        "### The Problem is Clear\n",
        "\n",
        "Both models are desperately trying to draw a straight line, but:\n",
        "\n",
        "- No single straight line can separate these two classes\n",
        "- We need a **curved** or **non-linear** decision boundary\n",
        "- Linear models are fundamentally limited!\n",
        "\n",
        "**So what's the solution?**\n",
        "\n",
        "---\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ldV6meNQL1XC"
      },
      "source": [
        "## 3.3 Model C: Multi-Layer Perceptron (MLP) to the Rescue!\n",
        "\n",
        "### What is an MLP?\n",
        "\n",
        "A **Multi-Layer Perceptron (MLP)** is your first **true neural network**!\n",
        "\n",
        "**Architecture:**\n",
        "\n",
        "```\n",
        "Input Layer â†’ Hidden Layer(s) â†’ Output Layer\n",
        "```\n",
        "\n",
        "**Key differences from Perceptron/Logistic Regression:**\n",
        "\n",
        "1. **Multiple layers**: It has \"hidden layers\" between input and output\n",
        "2. **Non-linear activation functions**: Usually ReLU (Rectified Linear Unit)\n",
        "3. **Can learn non-linear patterns**: By combining many simple units, it can create complex curved boundaries!\n",
        "\n",
        "**The Magic:**\n",
        "\n",
        "- Each neuron in the hidden layers learns a simple pattern\n",
        "- By combining many neurons across multiple layers, the network can learn complex patterns\n",
        "- It's like using many simple lines to approximate a complex curve!\n",
        "\n",
        "---\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zPcxIyFPL1XC"
      },
      "source": [
        "### TODO: Train the MLP\n",
        "\n",
        "Complete the code below to train the Multi-Layer Perceptron.\n",
        "\n",
        "**Model architecture:**\n",
        "\n",
        "- 2 hidden layers\n",
        "- 10 neurons in each hidden layer\n",
        "- ReLU activation function (for non-linearity)\n",
        "- Maximum 1000 training iterations\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "E_7rUmX7L1XC"
      },
      "outputs": [],
      "source": [
        "# --- TODO: Train the MLP model ---\n",
        "# Initialize the MLP model\n",
        "# hidden_layer_sizes=(10, 10) means 2 hidden layers with 10 neurons each\n",
        "# YOUR CODE HERE: model_mlp = MLPClassifier(...)\n",
        "# YOUR CODE HERE: model_mlp.fit(...)\n",
        "# YOUR CODE HERE: y_pred_mlp = ...\n",
        "\n",
        "# --- End of TODO ---\n",
        "\n",
        "\n",
        "# Calculate accuracy\n",
        "accuracy_mlp = accuracy_score(y_moons, y_pred_mlp)\n",
        "print(f\"MLP trained successfully!\")\n",
        "print(f\"Accuracy: {accuracy_mlp * 100:.2f}%\")\n",
        "print(f\"\\nCompare this to the linear models (~{accuracy_logreg_moons * 100:.0f}%)!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qZEPCIQ8L1XC"
      },
      "source": [
        "### The \"Aha!\" Moment: Visualize the MLP's Power\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "alQNV06YL1XC"
      },
      "outputs": [],
      "source": [
        "# Plot the MLP's decision boundary\n",
        "plot_decision_boundary(\n",
        "    X_moons,\n",
        "    y_moons,\n",
        "    model_mlp,\n",
        "    title=f\"MLP on Moons (Accuracy: {accuracy_mlp * 100:.2f}%) - SUCCESS! \",\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e0HxxeLRL1XC"
      },
      "source": [
        "## 3.4 Side-by-Side Comparison: The Moment of Truth\n",
        "\n",
        "Let's create a final comparison showing all three models on the same challenging dataset.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BTrvb2VDL1XC"
      },
      "outputs": [],
      "source": [
        "# Create a figure with 3 subplots\n",
        "fig, axes = plt.subplots(1, 3, figsize=(18, 5))\n",
        "\n",
        "models = [\n",
        "    (model_logreg_moons, \"Logistic Regression\", accuracy_logreg_moons),\n",
        "    (model_pct_moons, \"Perceptron\", accuracy_pct_moons),\n",
        "    (model_mlp, \"MLP (Neural Network)\", accuracy_mlp),\n",
        "]\n",
        "\n",
        "for idx, (model, name, acc) in enumerate(models):\n",
        "    ax = axes[idx]\n",
        "\n",
        "    # Set up the mesh grid\n",
        "    h = 0.02\n",
        "    x_min, x_max = X_moons[:, 0].min() - 0.5, X_moons[:, 0].max() + 0.5\n",
        "    y_min, y_max = X_moons[:, 1].min() - 0.5, X_moons[:, 1].max() + 0.5\n",
        "    xx, yy = np.meshgrid(np.arange(x_min, x_max, h), np.arange(y_min, y_max, h))\n",
        "\n",
        "    # Predict for each point in the mesh\n",
        "    Z = model.predict(np.c_[xx.ravel(), yy.ravel()])\n",
        "    Z = Z.reshape(xx.shape)\n",
        "\n",
        "    # Plot\n",
        "    cmap_light = ListedColormap([\"#FFAAAA\", \"#AAAAFF\"])\n",
        "    cmap_bold = ListedColormap([\"#FF0000\", \"#0000FF\"])\n",
        "\n",
        "    ax.contourf(xx, yy, Z, alpha=0.4, cmap=cmap_light)\n",
        "    ax.scatter(\n",
        "        X_moons[:, 0],\n",
        "        X_moons[:, 1],\n",
        "        c=y_moons,\n",
        "        cmap=cmap_bold,\n",
        "        edgecolor=\"black\",\n",
        "        s=30,\n",
        "        alpha=0.7,\n",
        "    )\n",
        "\n",
        "    ax.set_xlabel(\"Feature 1\")\n",
        "    ax.set_ylabel(\"Feature 2\")\n",
        "    ax.set_title(f\"{name}\\nAccuracy: {acc * 100:.2f}%\", fontsize=12, fontweight=\"bold\")\n",
        "    ax.grid(True, alpha=0.3)\n",
        "\n",
        "plt.suptitle(\n",
        "    \"The Power of Neural Networks: Linear vs Non-Linear Models\",\n",
        "    fontsize=16,\n",
        "    fontweight=\"bold\",\n",
        "    y=1.02,\n",
        ")\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "print(\"=\" * 70)\n",
        "print(\"FINAL COMPARISON: Linear Models vs Neural Network\")\n",
        "print(\"=\" * 70)\n",
        "print(\n",
        "    f\"Logistic Regression: {accuracy_logreg_moons * 100:6.2f}% - {'Single straight line (FAILING)' if accuracy_logreg_moons < 0.9 else 'Curved boundary (SUCCESS!) '}\"\n",
        ")\n",
        "print(\n",
        "    f\"Perceptron:          {accuracy_pct_moons * 100:6.2f}% - {'Single straight line (FAILING)' if accuracy_pct_moons < 0.9 else 'Curved boundary (SUCCESS!)'}\"\n",
        ")\n",
        "print(\n",
        "    f\"MLP:                 {accuracy_mlp * 100:6.2f}% - {'Single straight line (FAILING)' if accuracy_mlp < 0.95 else 'Curved boundary (SUCCESS!)'}\"\n",
        ")\n",
        "print(\"=\" * 70)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "34NbLN1VL1XC"
      },
      "source": [
        "## 3.5 Experimenting with Hyperparameters\n",
        "\n",
        "### What are Hyperparameters?\n",
        "\n",
        "**Hyperparameters** are settings you choose **before** training that control how the model learns.\n",
        "\n",
        "For an MLP, key hyperparameters include:\n",
        "\n",
        "1. **Number of hidden layers**: How many layers between input and output?\n",
        "2. **Number of neurons per layer**: How many units in each hidden layer?\n",
        "3. **Activation function**: Which non-linearity to use? (relu, tanh, sigmoid)\n",
        "4. **max_iter**: How many training iterations?\n",
        "\n",
        "**Key insight:** Different hyperparameters can dramatically affect performance!\n",
        "\n",
        "---\n",
        "\n",
        "### Your Experiment: Find the Best MLP Architecture\n",
        "\n",
        "You'll train **4 different MLP architectures** on the moons dataset and compare their performance.\n",
        "\n",
        "**Goal:** Understand how architecture choices affect model performance.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kz-LC3vQL1XC"
      },
      "source": [
        "### TODO: Train MLPs with Different Architectures\n",
        "\n",
        "Train the following 4 MLP models on the moons dataset and record their accuracy:\n",
        "\n",
        "1. **Tiny MLP**: `hidden_layer_sizes=(5,)` - Single layer with 5 neurons\n",
        "2. **Small MLP**: `hidden_layer_sizes=(10, 10)` - Two layers with 10 neurons each\n",
        "3. **Large MLP**: `hidden_layer_sizes=(50, 50)` - Two layers with 50 neurons each\n",
        "4. **Deep MLP**: `hidden_layer_sizes=(20, 20, 20)` - Three layers with 20 neurons each\n",
        "\n",
        "**For all models, use:**\n",
        "\n",
        "- `activation='relu'`\n",
        "- `max_iter=1000`\n",
        "- `random_state=42`\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "h9zCy2vEL1XC"
      },
      "outputs": [],
      "source": [
        "# First, split the moons data into train and test sets\n",
        "X_moons_train, X_moons_test, y_moons_train, y_moons_test = train_test_split(\n",
        "    X_moons, y_moons, test_size=0.2, random_state=42\n",
        ")\n",
        "\n",
        "# --- TODO: Train 4 different MLP architectures ---\n",
        "\n",
        "# 1. Tiny MLP: Single layer with 5 neurons\n",
        "# Train model and evaluate on test set\n",
        "mlp_tiny = MLPClassifier()\n",
        "\n",
        "\n",
        "# 2. Small MLP: Two layers with 10 neurons each\n",
        "# Train model and evaluate on test set\n",
        "mlp_small = MLPClassifier()\n",
        "\n",
        "\n",
        "# 3. Large MLP: Two layers with 50 neurons each\n",
        "# Train model and evaluate on test set\n",
        "mlp_large = MLPClassifier()\n",
        "\n",
        "# 4. Deep MLP: Three layers with 20 neurons each\n",
        "# Train model and evaluate on test set\n",
        "mlp_deep = MLPClassifier()\n",
        "\n",
        "# --- End of TODO ---\n",
        "\n",
        "# Print comparison table\n",
        "print(\"=\" * 70)\n",
        "print(\"MLP ARCHITECTURE COMPARISON (Test Set Performance)\")\n",
        "print(\"=\" * 70)\n",
        "print(f\"{'Architecture':<30} {'Neurons':<15} {'Accuracy':<10}\")\n",
        "print(\"-\" * 70)\n",
        "print(f\"{'Tiny (1 layer)':<30} {'5':<15} {acc_tiny * 100:>6.2f}%\")\n",
        "print(f\"{'Small (2 layers)':<30} {'10 + 10':<15} {acc_small * 100:>6.2f}%\")\n",
        "print(f\"{'Large (2 layers)':<30} {'50 + 50':<15} {acc_large * 100:>6.2f}%\")\n",
        "print(f\"{'Deep (3 layers)':<30} {'20 + 20 + 20':<15} {acc_deep * 100:>6.2f}%\")\n",
        "print(\"=\" * 70)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d8MwoogxL1XC"
      },
      "source": [
        "### Reflection Questions\n",
        "\n",
        "Based on your results:\n",
        "\n",
        "1. **Which architecture performed best?** Why do you think that is?\n",
        "2. **Does \"bigger\" always mean \"better\"?** Compare Tiny vs Large.\n",
        "3. **Does \"deeper\" always mean \"better\"?** Compare Small (2 layers) vs Deep (3 layers).\n",
        "4. **What's the trade-off?** Larger models have more parameters â†’ longer training time, risk of overfitting\n",
        "\n",
        "**Key insight:** There's often a \"sweet spot\" - not too small, not too large!\n",
        "\n",
        "---\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xevGs7RjL1XC"
      },
      "source": [
        "# Part 4: Real-World Application - Handwritten Digit Recognition\n",
        "\n",
        "## From Synthetic to Real Data\n",
        "\n",
        "So far, we've worked with **synthetic datasets** (artificially generated data like moons and circles).\n",
        "\n",
        "Now it's time to apply what you've learned to a **real-world computer vision dataset**!\n",
        "\n",
        "### The Dataset: MNIST Handwritten Digits\n",
        "\n",
        "We'll use the **MNIST dataset**, one of the most famous datasets in machine learning, containing handwritten digits (0-9).\n",
        "\n",
        "**Task:** Classify handwritten digits (0-9) based on 28Ã—28 pixel images.\n",
        "\n",
        "**Dataset Details:**\n",
        "\n",
        "- **70,000 grayscale images** (60,000 training + 10,000 test)\n",
        "- **28Ã—28 pixels** = **784 features** per image\n",
        "- **10 classes** (digits 0, 1, 2, 3, 4, 5, 6, 7, 8, 9)\n",
        "- Each pixel value ranges from 0 (white) to 255 (black)\n",
        "\n",
        "**This is a classic computer vision problem that launched the deep learning revolution!**\n",
        "\n",
        "---\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iDM5q6hYL1XC"
      },
      "source": [
        "## 4.1 Load and Explore the Data\n",
        "\n",
        "Let's start with loading the MNIST dataset and understanding its structure!\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MACrV_MlL1XC"
      },
      "outputs": [],
      "source": [
        "from sklearn.datasets import fetch_openml\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "# Load the MNIST dataset\n",
        "print(\"Loading MNIST dataset (this may take a moment)...\")\n",
        "mnist = fetch_openml(\"mnist_784\", version=1, parser=\"auto\")\n",
        "X_mnist = mnist.data.to_numpy() if hasattr(mnist.data, \"to_numpy\") else mnist.data\n",
        "y_mnist = (\n",
        "    mnist.target.astype(int).to_numpy()\n",
        "    if hasattr(mnist.target, \"to_numpy\")\n",
        "    else mnist.target.astype(int)\n",
        ")\n",
        "\n",
        "print(\"=\" * 70)\n",
        "print(\"MNIST DATASET INFORMATION\")\n",
        "print(\"=\" * 70)\n",
        "print(f\"Number of samples: {X_mnist.shape[0]}\")\n",
        "print(f\"Number of features: {X_mnist.shape[1]}\")\n",
        "print(f\"Image dimensions: 28Ã—28 pixels = {X_mnist.shape[1]} features\")\n",
        "print(f\"Number of classes: {len(np.unique(y_mnist))}\")\n",
        "print(f\"Class names: {sorted(np.unique(y_mnist))}\")\n",
        "\n",
        "print(\"\\n\" + \"=\" * 70)\n",
        "print(\"CLASS DISTRIBUTION\")\n",
        "print(\"=\" * 70)\n",
        "for digit in range(10):\n",
        "    count = sum(y_mnist == digit)\n",
        "    percentage = (count / len(y_mnist)) * 100\n",
        "    print(f\"Digit {digit}: {count} samples ({percentage:.1f}%)\")\n",
        "\n",
        "print(\"\\n  Notice: The dataset is well-balanced across all digits!\")\n",
        "print(\"=\" * 70)\n",
        "\n",
        "print(\"\\n\" + \"=\" * 70)\n",
        "print(\"FEATURE VALUE RANGES\")\n",
        "print(\"=\" * 70)\n",
        "print(f\"Min pixel value: {X_mnist.min()}\")\n",
        "print(f\"Max pixel value: {X_mnist.max()}\")\n",
        "print(f\"Data type: {X_mnist.dtype}\")\n",
        "print(\"\\n  Pixel values range from 0 (white) to 255 (black)\")\n",
        "print(\"=\" * 70)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0UBz51VSL1XC"
      },
      "outputs": [],
      "source": [
        "# Display sample statistics\n",
        "print(\"Statistical Summary (first 5 pixels):\")\n",
        "print(pd.DataFrame(X_mnist[:, :5]).describe())\n",
        "\n",
        "print(\"\\n\" + \"=\" * 70)\n",
        "print(\"SPARSITY ANALYSIS\")\n",
        "print(\"=\" * 70)\n",
        "# Count zero vs non-zero pixels\n",
        "total_pixels = X_mnist.size\n",
        "zero_pixels = np.sum(X_mnist == 0)\n",
        "nonzero_pixels = total_pixels - zero_pixels\n",
        "print(f\"Total pixels: {total_pixels:,}\")\n",
        "print(f\"Zero pixels (white): {zero_pixels:,} ({zero_pixels / total_pixels * 100:.1f}%)\")\n",
        "print(\n",
        "    f\"Non-zero pixels: {nonzero_pixels:,} ({nonzero_pixels / total_pixels * 100:.1f}%)\"\n",
        ")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9EKpJqy_L1XC"
      },
      "source": [
        "## 4.2 Visualize Sample Digits\n",
        "\n",
        "Let's visualize some handwritten digits from the dataset to understand what we're working with.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hHhfJAubL1XC"
      },
      "outputs": [],
      "source": [
        "# Visualize sample digits from each class\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "fig, axes = plt.subplots(2, 5, figsize=(12, 6))\n",
        "axes = axes.ravel()\n",
        "\n",
        "# Show one example of each digit (0-9)\n",
        "for digit in range(10):\n",
        "    # Find first occurrence of this digit\n",
        "    idx = np.where(y_mnist == digit)[0][0]\n",
        "\n",
        "    # Reshape 784-dimensional vector to 28Ã—28 image\n",
        "    image = X_mnist[idx].reshape(28, 28)\n",
        "\n",
        "    # Display the image\n",
        "    ax = axes[digit]\n",
        "    ax.imshow(image, cmap=\"gray\")\n",
        "    ax.set_title(f\"Digit: {digit}\", fontweight=\"bold\")\n",
        "    ax.axis(\"off\")\n",
        "\n",
        "plt.suptitle(\"Sample Handwritten Digits from MNIST\", fontsize=16, fontweight=\"bold\")\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# Show multiple examples of the same digit to see variation\n",
        "fig, axes = plt.subplots(2, 5, figsize=(12, 6))\n",
        "axes = axes.ravel()\n",
        "\n",
        "print(\"\\n\" + \"=\" * 70)\n",
        "print(\"SHOWING 10 DIFFERENT EXAMPLES OF DIGIT '3'\")\n",
        "print(\"=\" * 70)\n",
        "print(\"Notice the variation in handwriting styles!\")\n",
        "\n",
        "digit_to_show = 3\n",
        "indices = np.where(y_mnist == digit_to_show)[0][:10]\n",
        "\n",
        "for i, idx in enumerate(indices):\n",
        "    image = X_mnist[idx].reshape(28, 28)\n",
        "    ax = axes[i]\n",
        "    ax.imshow(image, cmap=\"gray\")\n",
        "    ax.set_title(f\"Sample {i + 1}\", fontsize=10)\n",
        "    ax.axis(\"off\")\n",
        "\n",
        "plt.suptitle(\n",
        "    f\"Variation in Handwriting: 10 Examples of Digit '{digit_to_show}'\",\n",
        "    fontsize=14,\n",
        "    fontweight=\"bold\",\n",
        ")\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A7GB74JkL1XC"
      },
      "source": [
        "## 4.3 Data Preprocessing: Train/Validation/Test Split\n",
        "\n",
        "### The Real-World Workflow: Three-Way Split\n",
        "\n",
        "In real machine learning projects, we use **THREE** datasets, not just two:\n",
        "\n",
        "1. **Training Set (48,000 samples)**: Used to train the model (update weights)\n",
        "2. **Validation Set (12,000 samples)**: Used to tune hyperparameters and detect overfitting\n",
        "3. **Test Set (10,000 samples)**: Used ONLY ONCE at the end to evaluate final performance\n",
        "\n",
        "**Why do we need a validation set?**\n",
        "\n",
        "- To detect **overfitting** during training\n",
        "- To tune hyperparameters (regularization strength, network size, etc.)\n",
        "- To decide when to stop training\n",
        "- To compare different models WITHOUT touching the test set\n",
        "\n",
        "**The Golden Rule:** The test set is like a sealed exam - you only open it once at the very end!\n",
        "\n",
        "---\n",
        "\n",
        "### Feature Scaling\n",
        "\n",
        "MNIST pixel values range from 0 to 255. We'll use **StandardScaler** to normalize all features to mean=0, std=1.\n",
        "\n",
        "**Why scale?**\n",
        "\n",
        "- Neural networks train much faster with normalized inputs\n",
        "- Prevents features with large ranges from dominating\n",
        "- Helps with gradient descent convergence\n",
        "\n",
        "---\n",
        "\n",
        "### TODO: Three-Way Split and Scaling\n",
        "\n",
        "Your task:\n",
        "\n",
        "1. MNIST comes with a standard split: first 60,000 for training, last 10,000 for test\n",
        "2. Further split the 60,000 training samples into train (48,000) and validation (12,000)\n",
        "3. Scale features using StandardScaler (fit on train only!)\n",
        "4. Final split: 48,000 train, 12,000 validation, 10,000 test\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5AlpL1CML1XC"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# --- TODO: Three-way split and scaling ---\n",
        "\n",
        "# Step 1: MNIST standard split - first 60,000 for train/val, last 10,000 for test\n",
        "\n",
        "\n",
        "# Step 2: Split the 60,000 into train (80%) and validation (20%)\n",
        "# This gives us 48,000 train and 12,000 validation\n",
        "\n",
        "\n",
        "# Step 3: Scale features (fit on train, transform all three sets)\n",
        "scaler = StandardScaler()\n",
        "\n",
        "\n",
        "# --- End of TODO ---\n",
        "\n",
        "print(\"Three-way split completed successfully!\")\n",
        "print(\"=\" * 70)\n",
        "print(\"DATASET SPLIT SUMMARY\")\n",
        "print(\"=\" * 70)\n",
        "print(\n",
        "    f\"Training set:   {X_mnist_train_scaled.shape[0]:,} samples ({X_mnist_train_scaled.shape[0] / len(X_mnist) * 100:.1f}%)\"\n",
        ")\n",
        "print(\n",
        "    f\"Validation set: {X_mnist_val_scaled.shape[0]:,} samples ({X_mnist_val_scaled.shape[0] / len(X_mnist) * 100:.1f}%)\"\n",
        ")\n",
        "print(\n",
        "    f\"Test set:       {X_mnist_test_scaled.shape[0]:,} samples ({X_mnist_test_scaled.shape[0] / len(X_mnist) * 100:.1f}%)\"\n",
        ")\n",
        "print(f\"Total:          {len(X_mnist):,} samples\")\n",
        "print(f\"Features:       {X_mnist_train_scaled.shape[1]} (28Ã—28 pixels)\")\n",
        "print(\"=\" * 70)\n",
        "\n",
        "# Check class distribution across all sets\n",
        "print(\"\\nCLASS DISTRIBUTION ACROSS SPLITS\")\n",
        "print(\"=\" * 70)\n",
        "for set_name, y_set in [\n",
        "    (\"Training\", y_mnist_train),\n",
        "    (\"Validation\", y_mnist_val),\n",
        "    (\"Test\", y_mnist_test),\n",
        "]:\n",
        "    print(f\"\\n{set_name} set:\")\n",
        "    for digit in range(10):\n",
        "        count = sum(y_set == digit)\n",
        "        percentage = (count / len(y_set)) * 100\n",
        "        print(f\"  Digit {digit}: {count:>5} samples ({percentage:.1f}%)\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s9gZFKlIL1XD"
      },
      "source": [
        "## 4.4 Detecting Overfitting with Validation Set (Optional)\n",
        "\n",
        "### What is Overfitting?\n",
        "\n",
        "**Overfitting** happens when a model learns the training data TOO well:\n",
        "\n",
        "- It \"memorizes\" the training data instead of learning general patterns\n",
        "- Training accuracy is high, but validation/test accuracy is low\n",
        "- The model doesn't generalize to new data\n",
        "\n",
        "**Visual analogy:**\n",
        "\n",
        "- **Underfitting**: Drawing a straight line through a curve (too simple)\n",
        "- **Good fit**: Capturing the general trend\n",
        "- **Overfitting**: Drawing a crazy curve that passes through every single point (too complex)\n",
        "\n",
        "### Why MNIST is Perfect for Demonstrating Overfitting\n",
        "\n",
        "With 784 features and complex patterns:\n",
        "\n",
        "- Large neural networks can easily **memorize** the 48,000 training images\n",
        "- Without regularization, you'll see training accuracy â†’ 100% but validation accuracy stagnates\n",
        "- This dramatic gap clearly shows overfitting in action!\n",
        "\n",
        "### How to Detect Overfitting\n",
        "\n",
        "Compare performance on training vs validation set:\n",
        "\n",
        "- **Train accuracy >> Validation accuracy**: OVERFITTING!\n",
        "- **Train accuracy â‰ˆ Validation accuracy**: Good generalization âœ“\n",
        "\n",
        "Let's train models and watch for overfitting!\n",
        "\n",
        "---\n",
        "\n",
        "### TODO: Train Models and Monitor Overfitting\n",
        "\n",
        "We'll train 3 models and evaluate on BOTH train and validation sets:\n",
        "\n",
        "1. **Logistic Regression** - linear baseline (multi-class)\n",
        "2. **MLP without regularization** - will definitely overfit!\n",
        "3. **MLP with L2 regularization** - prevents overfitting\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cOjTmFXEL1XD"
      },
      "outputs": [],
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# --- TODO: Train models and compare train vs validation performance ---\n",
        "\n",
        "print(\"=\" * 70)\n",
        "print(\"TRAINING MODELS WITH OVERFITTING DETECTION\")\n",
        "print(\"=\" * 70)\n",
        "\n",
        "# Model 1: Logistic Regression (multi-class, has built-in L2 regularization)\n",
        "print(\"\\n1. Training Logistic Regression (linear baseline)...\")\n",
        "\n",
        "\n",
        "# Evaluate on BOTH train and validation sets\n",
        "\n",
        "\n",
        "print(f\"   Train Accuracy: {train_acc_logreg * 100:.2f}%\")\n",
        "print(f\"   Val Accuracy:   {val_acc_logreg * 100:.2f}%\")\n",
        "print(\n",
        "    f\"   Gap:            {(val_acc_logreg - train_acc_logreg) * 100:+.2f}% {'âœ“ Good' if abs(train_acc_logreg - val_acc_logreg) < 0.05 else 'âš  Some gap'}\"\n",
        ")\n",
        "\n",
        "# Model 2: MLP WITHOUT regularization (alpha=0) - WILL overfit!\n",
        "print(\"\\n2. Training MLP WITHOUT regularization (alpha=0)...\")\n",
        "print(\"   (MLP: 32 â†’ 16 neurons, this will take longer...)\")\n",
        "\n",
        "# Evaluate on BOTH train and validation sets\n",
        "\n",
        "\n",
        "print(f\"   Train Accuracy: {train_acc_mlp_no_reg * 100:.2f}%\")\n",
        "print(f\"   Val Accuracy:   {val_acc_mlp_no_reg * 100:.2f}%\")\n",
        "print(\n",
        "    f\"   Gap:            {(val_acc_mlp_no_reg - train_acc_mlp_no_reg) * 100:+.2f}% {'âœ“ Good' if abs(train_acc_mlp_no_reg - val_acc_mlp_no_reg) < 0.05 else 'âš  OVERFITTING!'}\"\n",
        ")\n",
        "\n",
        "# Model 3: MLP WITH L2 regularization (alpha=0.05)\n",
        "print(\"\\n3. Training MLP WITH L2 regularization (alpha=0.05)...\")\n",
        "\n",
        "\n",
        "# Evaluate on BOTH train and validation sets\n",
        "\n",
        "\n",
        "print(f\"   Train Accuracy: {train_acc_mlp_l2 * 100:.2f}%\")\n",
        "print(f\"   Val Accuracy:   {val_acc_mlp_l2 * 100:.2f}%\")\n",
        "print(\n",
        "    f\"   Gap:            {(val_acc_mlp_l2 - train_acc_mlp_l2) * 100:+.2f}% {'âœ“ Good generalization!' if abs(train_acc_mlp_l2 - val_acc_mlp_l2) < 0.05 else 'âš  Some overfitting'}\"\n",
        ")\n",
        "\n",
        "# --- End of TODO ---\n",
        "\n",
        "print(\"\\n\" + \"=\" * 70)\n",
        "print(\"OVERFITTING ANALYSIS\")\n",
        "print(\"=\" * 70)\n",
        "print(f\"{'Model':<35} {'Train Acc':<12} {'Val Acc':<12} {'Gap':<12} {'Status'}\")\n",
        "print(\"-\" * 70)\n",
        "\n",
        "models_analysis = [\n",
        "    (\"Logistic Regression (linear)\", train_acc_logreg, val_acc_logreg),\n",
        "    (\"MLP (no regularization)\", train_acc_mlp_no_reg, val_acc_mlp_no_reg),\n",
        "    (\"MLP (L2 regularization)\", train_acc_mlp_l2, val_acc_mlp_l2),\n",
        "]\n",
        "\n",
        "for name, train_acc, val_acc in models_analysis:\n",
        "    gap = val_acc - train_acc\n",
        "    status = \"âœ“ Good\" if abs(gap) < 0.05 else \"âš  Overfitting\"\n",
        "    print(\n",
        "        f\"{name:<35} {train_acc * 100:>6.2f}%     {val_acc * 100:>6.2f}%     {gap * 100:>+6.2f}%    {status}\"\n",
        "    )\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Sq3hCtZtL1XD"
      },
      "source": [
        "## 4.5 Understanding Regularization: L1 vs L2 (Optional)\n",
        "\n",
        "### What is Regularization?\n",
        "\n",
        "**Regularization** adds a penalty term to the loss function to prevent overfitting:\n",
        "\n",
        "**Original loss:** $Loss = Error(predictions, true\\_values)$\n",
        "\n",
        "**With regularization:** $Loss = Error + \\lambda \\times Penalty(weights)$\n",
        "\n",
        "Where $\\lambda$ (alpha in sklearn) controls the strength of regularization.\n",
        "\n",
        "---\n",
        "\n",
        "### L1 vs L2 Regularization\n",
        "\n",
        "**L2 Regularization (Ridge):**\n",
        "\n",
        "- Penalty: $\\lambda \\sum w_i^2$ (sum of squared weights)\n",
        "- Effect: Shrinks ALL weights toward zero\n",
        "- Result: Weights become small but rarely exactly zero\n",
        "- Use when: All features might be useful\n",
        "\n",
        "**L1 Regularization (Lasso):**\n",
        "\n",
        "- Penalty: $\\lambda \\sum |w_i|$ (sum of absolute weights)\n",
        "- Effect: Can set some weights to EXACTLY zero\n",
        "- Result: Performs automatic feature selection\n",
        "- Use when: You suspect many features are irrelevant\n",
        "\n",
        "**Elastic Net:**\n",
        "\n",
        "- Combines both L1 and L2\n",
        "- Best of both worlds!\n",
        "\n",
        "---\n",
        "\n",
        "### Choosing the Right Alpha (Regularization Strength)\n",
        "\n",
        "Let's test different alpha values and see their effect!\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wo-XAjNQL1XD"
      },
      "outputs": [],
      "source": [
        "# Test different alpha values for L2 regularization\n",
        "print(\"=\" * 70)\n",
        "print(\"REGULARIZATION STRENGTH EXPERIMENT (L2)\")\n",
        "print(\"=\" * 70)\n",
        "print(\"Testing different alpha values to find the sweet spot...\")\n",
        "print(\"(This will take a few minutes...)\")\n",
        "print()\n",
        "\n",
        "# Test alphas from no regularization to strong regularization\n",
        "alphas = [0, 0.0001, 0.001, 0.01, 0.1, 1.0]\n",
        "train_accs = []\n",
        "val_accs = []\n",
        "\n",
        "for alpha in alphas:\n",
        "    print(f\"Training with alpha={alpha}...\", end=\" \")\n",
        "    mlp = MLPClassifier(\n",
        "        hidden_layer_sizes=(32, 16),\n",
        "        alpha=alpha,\n",
        "        max_iter=50,\n",
        "        random_state=42,\n",
        "        early_stopping=False,\n",
        "        verbose=False,\n",
        "    )\n",
        "    mlp.fit(X_mnist_train_scaled, y_mnist_train)\n",
        "\n",
        "    train_acc = accuracy_score(y_mnist_train, mlp.predict(X_mnist_train_scaled))\n",
        "    val_acc = accuracy_score(y_mnist_val, mlp.predict(X_mnist_val_scaled))\n",
        "\n",
        "    train_accs.append(train_acc)\n",
        "    val_accs.append(val_acc)\n",
        "\n",
        "    gap = val_acc - train_acc\n",
        "    print(\n",
        "        f\"Train: {train_acc * 100:.2f}%, Val: {val_acc * 100:.2f}%, Gap: {gap * 100:+.2f}%\"\n",
        "    )\n",
        "\n",
        "print(\"\\n\" + \"=\" * 70)\n",
        "print(\"SUMMARY TABLE\")\n",
        "print(\"=\" * 70)\n",
        "print(f\"{'Alpha':<12} {'Train Acc':<12} {'Val Acc':<12} {'Gap':<12} {'Status'}\")\n",
        "print(\"-\" * 70)\n",
        "for i, alpha in enumerate(alphas):\n",
        "    gap = train_accs[i] - val_accs[i]\n",
        "    status = \"âœ“\" if abs(gap) < 0.05 else \"âš  Overfit\" if gap > 0.05 else \"âš  Underfit\"\n",
        "    print(\n",
        "        f\"{alpha:<12.4f} {train_accs[i] * 100:>6.2f}%     {val_accs[i] * 100:>6.2f}%     {gap * 100:>+6.2f}%    {status}\"\n",
        "    )\n",
        "print(\"=\" * 70)\n",
        "\n",
        "# Visualize the effect of regularization\n",
        "plt.figure(figsize=(12, 5))\n",
        "\n",
        "# Plot 1: Accuracy vs Alpha\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(\n",
        "    range(len(alphas)),\n",
        "    [acc * 100 for acc in train_accs],\n",
        "    \"o-\",\n",
        "    label=\"Train Accuracy\",\n",
        "    linewidth=2,\n",
        "    markersize=8,\n",
        "    color=\"blue\",\n",
        ")\n",
        "plt.plot(\n",
        "    range(len(alphas)),\n",
        "    [acc * 100 for acc in val_accs],\n",
        "    \"s-\",\n",
        "    label=\"Validation Accuracy\",\n",
        "    linewidth=2,\n",
        "    markersize=8,\n",
        "    color=\"orange\",\n",
        ")\n",
        "plt.xticks(range(len(alphas)), [f\"{a:.4f}\" for a in alphas], rotation=45)\n",
        "plt.xlabel(\"Alpha (Regularization Strength)\", fontweight=\"bold\")\n",
        "plt.ylabel(\"Accuracy (%)\", fontweight=\"bold\")\n",
        "plt.title(\"Effect of L2 Regularization on MNIST\", fontweight=\"bold\", fontsize=14)\n",
        "plt.legend()\n",
        "plt.grid(True, alpha=0.3)\n",
        "plt.ylim(\n",
        "    [\n",
        "        min(min(train_accs), min(val_accs)) * 100 - 2,\n",
        "        max(max(train_accs), max(val_accs)) * 100 + 2,\n",
        "    ]\n",
        ")\n",
        "\n",
        "# Plot 2: Train-Val Gap (Overfitting Measure)\n",
        "plt.subplot(1, 2, 2)\n",
        "gaps = [(train - val) * 100 for train, val in zip(train_accs, val_accs)]\n",
        "colors = [\"red\" if gap > 10 else \"orange\" if gap > 5 else \"green\" for gap in gaps]\n",
        "bars = plt.bar(\n",
        "    range(len(alphas)), gaps, color=colors, alpha=0.7, edgecolor=\"black\", linewidth=1.5\n",
        ")\n",
        "plt.xticks(range(len(alphas)), [f\"{a:.4f}\" for a in alphas], rotation=45)\n",
        "plt.xlabel(\"Alpha (Regularization Strength)\", fontweight=\"bold\")\n",
        "plt.ylabel(\"Train-Val Gap (%)\", fontweight=\"bold\")\n",
        "plt.title(\"Overfitting Gap (Lower is Better)\", fontweight=\"bold\", fontsize=14)\n",
        "plt.axhline(\n",
        "    y=10,\n",
        "    color=\"red\",\n",
        "    linestyle=\"--\",\n",
        "    alpha=0.5,\n",
        "    label=\"Severe overfitting\",\n",
        "    linewidth=1,\n",
        ")\n",
        "plt.axhline(\n",
        "    y=5,\n",
        "    color=\"orange\",\n",
        "    linestyle=\"--\",\n",
        "    alpha=0.5,\n",
        "    label=\"Moderate overfitting\",\n",
        "    linewidth=1,\n",
        ")\n",
        "plt.axhline(y=0, color=\"black\", linestyle=\"-\", alpha=0.3, linewidth=0.5)\n",
        "plt.legend()\n",
        "plt.grid(True, alpha=0.3, axis=\"y\")\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# Find best alpha (smallest gap while maintaining good validation accuracy)\n",
        "best_idx = np.argmax(val_accs)  # Choose alpha with best validation accuracy\n",
        "best_alpha = alphas[best_idx]\n",
        "\n",
        "print(f\"\\nBest alpha (highest validation accuracy): {best_alpha}\")\n",
        "print(f\"   Train Accuracy: {train_accs[best_idx] * 100:.2f}%\")\n",
        "print(f\"   Val Accuracy: {val_accs[best_idx] * 100:.2f}%\")\n",
        "print(f\"   Gap: {gaps[best_idx]:+.2f}%\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1lKjNBwrL1XD"
      },
      "source": [
        "## 4.6 Final Model Selection and Training\n",
        "\n",
        "### The Complete Workflow: From Hyperparameter Tuning to Final Model\n",
        "\n",
        "Now that we've used the **validation set** to find the best hyperparameters (alpha), we need to follow the industry-standard workflow:\n",
        "\n",
        "**Step 1: Select Best Model**\n",
        "\n",
        "- Based on validation performance, choose the best configuration\n",
        "\n",
        "**Step 2: Retrain on Train + Validation**\n",
        "\n",
        "- Combine train and validation sets\n",
        "- Retrain the final model with the best hyperparameters\n",
        "- This uses all available training data for the final model\n",
        "\n",
        "**Step 3: Evaluate ONCE on Test Set**\n",
        "\n",
        "- Use the test set (which we haven't touched yet!)\n",
        "- Get an unbiased estimate of real-world performance\n",
        "\n",
        "**Why retrain on train+val?**\n",
        "\n",
        "- More data â†’ better model\n",
        "- Validation set already did its job (tuning hyperparameters)\n",
        "- Test set is truly unseen data\n",
        "\n",
        "---\n",
        "\n",
        "### TODO: Select Best Model and Retrain\n",
        "\n",
        "Based on our experiments, let's select the best model and retrain it on the combined train+validation set.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4Hq39BjvL1XD"
      },
      "outputs": [],
      "source": [
        "# --- TODO: Retrain best models on train+validation ---\n",
        "\n",
        "print(\"=\" * 70)\n",
        "print(\"FINAL MODEL TRAINING (on Train + Validation)\")\n",
        "print(\"=\" * 70)\n",
        "\n",
        "\n",
        "# Combine train and validation sets\n",
        "# YOUR CODE HERE: X_train_val = ...\n",
        "# YOUR CODE HERE: y_train_val = ...\n",
        "\n",
        "print(f\"Combined training set size: {X_train_val.shape[0]:,} samples\")\n",
        "print(f\"Test set size (still sealed!): {X_mnist_test_scaled.shape[0]:,} samples\")\n",
        "print()\n",
        "\n",
        "# Model 1: Logistic Regression (final)\n",
        "print(\"Training final Logistic Regression model...\")\n",
        "# YOUR CODE HERE: final_logreg = ...\n",
        "# YOUR CODE HERE: final_logreg.fit(...)\n",
        "print(\"Logistic Regression trained on train+val\")\n",
        "\n",
        "# Model 2: MLP with best alpha from experiment\n",
        "print(\"\\nTraining final MLP (32, 16) with best alpha...\")\n",
        "# YOUR CODE HERE: final_mlp_small = ...\n",
        "# YOUR CODE HERE: final_mlp_small.fit(...)\n",
        "\n",
        "print(\"MLP (32, 16) trained on train+val\")\n",
        "\n",
        "# Model 3: Larger MLP for comparison\n",
        "print(\"\\nTraining final MLP (64, 32) with alpha=0.001...\")\n",
        "# YOUR CODE HERE: final_mlp_large = ...\n",
        "# YOUR CODE HERE: final_mlp_large.fit(...)\n",
        "\n",
        "\n",
        "print(\"MLP (64, 32) trained on train+val\")\n",
        "\n",
        "# --- End of TODO ---\n",
        "\n",
        "print(\"\\n\" + \"=\" * 70)\n",
        "print(\"All final models trained successfully!\")\n",
        "print(\"=\" * 70)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w-lapAgrL1XD"
      },
      "source": [
        "## 4.7 Final Test Set Evaluation\n",
        "\n",
        "### Opening the \"Sealed Exam\"\n",
        "\n",
        "We've completed all our model development and hyperparameter tuning using only the train and validation sets. Now it's time to evaluate on the **test set** - data our models have NEVER seen!\n",
        "\n",
        "**Why is this important?**\n",
        "\n",
        "- The test set gives us an **unbiased estimate** of how the model will perform on new, real-world data\n",
        "- If we had used the test set during development, we might have unknowingly tuned our models to it (data leakage!)\n",
        "- This is the industry standard for reporting final model performance\n",
        "\n",
        "**What to expect:**\n",
        "\n",
        "- Test performance should be similar to validation performance (if we did everything right!)\n",
        "- If test performance is much worse â†’ we might have overfit to the validation set\n",
        "- If test performance is much better â†’ we got lucky (or something went wrong!)\n",
        "\n",
        "---\n",
        "\n",
        "### TODO: Evaluate All Models on Test Set\n",
        "\n",
        "Let's evaluate our three final models on the test set and compare their performance.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RgIASeGcL1XD"
      },
      "outputs": [],
      "source": [
        "# --- TODO: Evaluate on test set ---\n",
        "\n",
        "print(\"=\" * 70)\n",
        "print(\"UNSEALING THE TEST SET - FINAL EVALUATION\")\n",
        "print(\"=\" * 70)\n",
        "print(\"\\nEvaluating all models on the test set...\\n\")\n",
        "\n",
        "# Model 1: Logistic Regression\n",
        "# y_pred_mnist_logreg = ...\n",
        "# acc_mnist_logreg = ...\n",
        "\n",
        "print(f\"1. Logistic Regression\")\n",
        "print(f\"   Test Accuracy: {acc_mnist_logreg * 100:.2f}%\")\n",
        "\n",
        "# Model 2: MLP (32, 16)\n",
        "# y_pred_mnist_mlp_large = ...\n",
        "# acc_mnist_mlp_large = ...\n",
        "\n",
        "print(f\"\\n2. MLP (32, 16) \")\n",
        "print(f\"   Test Accuracy: {acc_mnist_mlp_small * 100:.2f}%\")\n",
        "\n",
        "# Model 3: MLP (64, 32)\n",
        "# y_pred_mnist_mlp_small = ...\n",
        "# acc_mnist_mlp_small = ...\n",
        "\n",
        "print(f\"\\n3. MLP (64, 32)\")\n",
        "print(f\"   Test Accuracy: {acc_mnist_mlp_large * 100:.2f}%\")\n",
        "\n",
        "# --- End of TODO ---\n",
        "\n",
        "print(\"\\n\" + \"=\" * 70)\n",
        "print(\"MODEL COMPARISON ON TEST SET\")\n",
        "print(\"=\" * 70)\n",
        "print(f\"{'Model':<30} {'Test Accuracy':<15} {'Status'}\")\n",
        "print(\"-\" * 70)\n",
        "print(\n",
        "    f\"{'Logistic Regression':<30} {acc_mnist_logreg * 100:>6.2f}%        {'âœ“ Baseline (linear)'}\"\n",
        ")\n",
        "print(\n",
        "    f\"{'MLP (32, 16)':<30} {acc_mnist_mlp_small * 100:>6.2f}%        {'Small network'}\"\n",
        ")\n",
        "print(\n",
        "    f\"{'MLP (64, 32)':<30} {acc_mnist_mlp_large * 100:>6.2f}%        {'Larger network'}\"\n",
        ")\n",
        "print(\"=\" * 70)\n",
        "\n",
        "# Determine best model\n",
        "best_acc = max(acc_mnist_logreg, acc_mnist_mlp_small, acc_mnist_mlp_large)\n",
        "if best_acc == acc_mnist_logreg:\n",
        "    best_model_name = \"Logistic Regression\"\n",
        "elif best_acc == acc_mnist_mlp_small:\n",
        "    best_model_name = \"MLP (32, 16)\"\n",
        "else:\n",
        "    best_model_name = \"MLP (64, 32)\"\n",
        "\n",
        "print(f\"\\nBest Model: {best_model_name} with {best_acc * 100:.2f}% test accuracy\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qraopo3-L1XD"
      },
      "source": [
        "## 4.8 Confusion Matrix Analysis\n",
        "\n",
        "### Understanding Model Errors in Multi-Class Classification\n",
        "\n",
        "Now let's visualize where our models make mistakes using confusion matrices.\n",
        "\n",
        "**Confusion Matrix for 10 classes:**\n",
        "\n",
        "- **Rows**: True labels (actual digits)\n",
        "- **Columns**: Predicted labels\n",
        "- **Diagonal**: Correct predictions\n",
        "- **Off-diagonal**: Mistakes (e.g., predicting 8 when it's actually 3)\n",
        "\n",
        "**Common confusions in MNIST:**\n",
        "\n",
        "- **3 â†” 5**: Similar curved shapes\n",
        "- **4 â†” 9**: Overlapping features\n",
        "- **7 â†” 1**: Can look similar with certain handwriting\n",
        "- **8 â†” 3**: Loops can be ambiguous\n",
        "\n",
        "Let's visualize where each model makes mistakes!\n",
        "\n",
        "---\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nf_4ypx8L1XD"
      },
      "source": [
        "### Confusion Matrix Visualization\n",
        "\n",
        "Let's visualize the confusion matrices for all three models to see where they make mistakes.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wb-4-eHTL1XD"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
        "\n",
        "# Create confusion matrices for all three models\n",
        "fig, axes = plt.subplots(1, 3, figsize=(20, 6))\n",
        "\n",
        "models_to_viz = [\n",
        "    (y_pred_mnist_logreg, \"Logistic Regression\", acc_mnist_logreg),\n",
        "    (y_pred_mnist_mlp_small, \"MLP (32, 16)\", acc_mnist_mlp_small),\n",
        "    (y_pred_mnist_mlp_large, \"MLP (64, 32)\", acc_mnist_mlp_large),\n",
        "]\n",
        "\n",
        "for idx, (y_pred, model_name, acc) in enumerate(models_to_viz):\n",
        "    ax = axes[idx]\n",
        "\n",
        "    cm = confusion_matrix(y_mnist_test, y_pred)\n",
        "    disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=range(10))\n",
        "    disp.plot(cmap=\"Blues\", ax=ax, values_format=\"d\", colorbar=False, im_kw={\"vmin\": 0})\n",
        "    ax.set_title(\n",
        "        f\"{model_name}\\nAccuracy: {acc * 100:.2f}%\", fontweight=\"bold\", fontsize=12\n",
        "    )\n",
        "    ax.set_xlabel(\"Predicted Digit\", fontweight=\"bold\")\n",
        "    ax.set_ylabel(\"True Digit\", fontweight=\"bold\")\n",
        "\n",
        "plt.suptitle(\n",
        "    \"Confusion Matrices: Comparing Model Errors on MNIST Test Set\",\n",
        "    fontsize=16,\n",
        "    fontweight=\"bold\",\n",
        ")\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# Analyze common misclassifications for best model\n",
        "best_model_idx = np.argmax([acc_mnist_logreg, acc_mnist_mlp_small, acc_mnist_mlp_large])\n",
        "best_pred = models_to_viz[best_model_idx][0]\n",
        "best_name = models_to_viz[best_model_idx][1]\n",
        "\n",
        "cm_best = confusion_matrix(y_mnist_test, best_pred)\n",
        "\n",
        "print(\"\\n\" + \"=\" * 70)\n",
        "print(f\"CONFUSION ANALYSIS FOR BEST MODEL: {best_name}\")\n",
        "print(\"=\" * 70)\n",
        "\n",
        "# Find most common misclassifications\n",
        "misclassifications = []\n",
        "for i in range(10):\n",
        "    for j in range(10):\n",
        "        if i != j and cm_best[i, j] > 0:\n",
        "            misclassifications.append((cm_best[i, j], i, j))\n",
        "\n",
        "misclassifications.sort(reverse=True)\n",
        "\n",
        "print(\"\\nTop 10 Most Common Mistakes:\")\n",
        "print(f\"{'Count':<8} {'Actual':<10} {'Predicted':<10} {'Error Type'}\")\n",
        "print(\"-\" * 70)\n",
        "for count, actual, predicted in misclassifications[:10]:\n",
        "    print(\n",
        "        f\"{count:<8} {actual:<10} {predicted:<10} {actual} misclassified as {predicted}\"\n",
        "    )\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jg99HDruL1XD"
      },
      "source": [
        "## 4.9 Per-Class Performance Metrics\n",
        "\n",
        "### Beyond Overall Accuracy: Class-Level Analysis\n",
        "\n",
        "For multi-class problems, **overall accuracy** can hide important details. We need to understand:\n",
        "\n",
        "1. **Precision (per class)**: Of all predictions for digit X, how many were correct?\n",
        "\n",
        "   - Formula: $Precision_i = \\frac{TP_i}{TP_i + FP_i}$\n",
        "   - High precision â†’ Few false alarms for this class\n",
        "\n",
        "2. **Recall (per class)**: Of all actual instances of digit X, how many did we catch?\n",
        "\n",
        "   - Formula: $Recall_i = \\frac{TP_i}{TP_i + FN_i}$\n",
        "   - High recall â†’ Rarely miss this digit\n",
        "\n",
        "3. **F1-Score (per class)**: Harmonic mean of precision and recall\n",
        "   - Formula: $F1_i = 2 \\times \\frac{Precision_i \\times Recall_i}{Precision_i + Recall_i}$\n",
        "   - Balances both metrics\n",
        "\n",
        "**Why this matters:**\n",
        "\n",
        "- Some digits might be easier/harder to classify\n",
        "- Identifies which classes need more attention\n",
        "- Helps understand model strengths and weaknesses\n",
        "\n",
        "---\n",
        "\n",
        "Let's calculate precision, recall, and F1-score for each digit (0-9).\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3-m9uLXSL1XD"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import classification_report, precision_recall_fscore_support\n",
        "\n",
        "\n",
        "print(\"=\" * 70)\n",
        "print(\"PER-CLASS PERFORMANCE METRICS\")\n",
        "print(\"=\" * 70)\n",
        "\n",
        "# Get the best model's predictions\n",
        "best_model_idx = np.argmax([acc_mnist_logreg, acc_mnist_mlp_small, acc_mnist_mlp_large])\n",
        "best_pred = models_to_viz[best_model_idx][0]\n",
        "best_name = models_to_viz[best_model_idx][1]\n",
        "\n",
        "print(f\"\\nDetailed Classification Report for: {best_name}\")\n",
        "print(\"=\" * 70)\n",
        "print(classification_report(y_mnist_test, best_pred, digits=3))\n",
        "\n",
        "# Calculate per-class metrics for visualization\n",
        "precision, recall, f1, support = precision_recall_fscore_support(\n",
        "    y_mnist_test, best_pred, labels=range(10)\n",
        ")\n",
        "\n",
        "# Visualize per-class performance\n",
        "fig, axes = plt.subplots(1, 3, figsize=(18, 5))\n",
        "\n",
        "# Plot 1: Precision by digit\n",
        "ax1 = axes[0]\n",
        "bars1 = ax1.bar(\n",
        "    range(10), precision * 100, color=\"skyblue\", edgecolor=\"black\", linewidth=1.5\n",
        ")\n",
        "ax1.set_xlabel(\"Digit\", fontweight=\"bold\", fontsize=12)\n",
        "ax1.set_ylabel(\"Precision (%)\", fontweight=\"bold\", fontsize=12)\n",
        "ax1.set_title(f\"Precision by Digit\\n({best_name})\", fontweight=\"bold\", fontsize=14)\n",
        "ax1.set_xticks(range(10))\n",
        "ax1.set_ylim([min(precision) * 100 - 5, 100])\n",
        "ax1.grid(True, alpha=0.3, axis=\"y\")\n",
        "ax1.axhline(\n",
        "    y=np.mean(precision) * 100,\n",
        "    color=\"red\",\n",
        "    linestyle=\"--\",\n",
        "    label=f\"Mean: {np.mean(precision) * 100:.1f}%\",\n",
        "    linewidth=2,\n",
        ")\n",
        "ax1.legend()\n",
        "\n",
        "# Plot 2: Recall by digit\n",
        "ax2 = axes[1]\n",
        "bars2 = ax2.bar(\n",
        "    range(10), recall * 100, color=\"lightcoral\", edgecolor=\"black\", linewidth=1.5\n",
        ")\n",
        "ax2.set_xlabel(\"Digit\", fontweight=\"bold\", fontsize=12)\n",
        "ax2.set_ylabel(\"Recall (%)\", fontweight=\"bold\", fontsize=12)\n",
        "ax2.set_title(f\"Recall by Digit\\n({best_name})\", fontweight=\"bold\", fontsize=14)\n",
        "ax2.set_xticks(range(10))\n",
        "ax2.set_ylim([min(recall) * 100 - 5, 100])\n",
        "ax2.grid(True, alpha=0.3, axis=\"y\")\n",
        "ax2.axhline(\n",
        "    y=np.mean(recall) * 100,\n",
        "    color=\"red\",\n",
        "    linestyle=\"--\",\n",
        "    label=f\"Mean: {np.mean(recall) * 100:.1f}%\",\n",
        "    linewidth=2,\n",
        ")\n",
        "ax2.legend()\n",
        "\n",
        "# Plot 3: F1-Score by digit\n",
        "ax3 = axes[2]\n",
        "bars3 = ax3.bar(\n",
        "    range(10), f1 * 100, color=\"lightgreen\", edgecolor=\"black\", linewidth=1.5\n",
        ")\n",
        "ax3.set_xlabel(\"Digit\", fontweight=\"bold\", fontsize=12)\n",
        "ax3.set_ylabel(\"F1-Score (%)\", fontweight=\"bold\", fontsize=12)\n",
        "ax3.set_title(f\"F1-Score by Digit\\n({best_name})\", fontweight=\"bold\", fontsize=14)\n",
        "ax3.set_xticks(range(10))\n",
        "ax3.set_ylim([min(f1) * 100 - 5, 100])\n",
        "ax3.grid(True, alpha=0.3, axis=\"y\")\n",
        "ax3.axhline(\n",
        "    y=np.mean(f1) * 100,\n",
        "    color=\"red\",\n",
        "    linestyle=\"--\",\n",
        "    label=f\"Mean: {np.mean(f1) * 100:.1f}%\",\n",
        "    linewidth=2,\n",
        ")\n",
        "ax3.legend()\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "\n",
        "# Find best and worst performing digits\n",
        "best_digit = np.argmax(f1)\n",
        "worst_digit = np.argmin(f1)\n",
        "\n",
        "print(\"\\n\" + \"=\" * 70)\n",
        "print(\"PERFORMANCE SUMMARY BY DIGIT\")\n",
        "print(\"=\" * 70)\n",
        "print(f\"\\n{'Digit':<8} {'Precision':<12} {'Recall':<12} {'F1-Score':<12} {'Support'}\")\n",
        "print(\"-\" * 70)\n",
        "for digit in range(10):\n",
        "    print(\n",
        "        f\"{digit:<8} {precision[digit] * 100:>6.2f}%     {recall[digit] * 100:>6.2f}%     \"\n",
        "        f\"{f1[digit] * 100:>6.2f}%     {support[digit]:>6}\"\n",
        "    )\n",
        "print(\"=\" * 70)\n",
        "\n",
        "print(f\"\\nBest performing digit: {best_digit} (F1: {f1[best_digit] * 100:.2f}%)\")\n",
        "print(f\"Worst performing digit: {worst_digit} (F1: {f1[worst_digit] * 100:.2f}%)\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RL2M5j5_L1XD"
      },
      "source": [
        "## 4.10 Visualizing What the Model Learned\n",
        "\n",
        "### Understanding Pixel Importance\n",
        "\n",
        "In MNIST, each of the 784 features is a pixel. We can visualize which pixels are most important for classification!\n",
        "\n",
        "**For Logistic Regression:**\n",
        "\n",
        "- For each digit class, we have 784 weights (one per pixel)\n",
        "- Positive weights â†’ Pixel brightness increases probability of this digit\n",
        "- Negative weights â†’ Pixel darkness increases probability of this digit\n",
        "- We can reshape these weights back into 28Ã—28 images!\n",
        "\n",
        "**What will we see?**\n",
        "\n",
        "- Dark regions â†’ Important for identifying the digit\n",
        "- Light regions â†’ Not important\n",
        "- This gives us insight into what the model \"looks for\" when classifying\n",
        "\n",
        "**For example:**\n",
        "\n",
        "- Digit \"1\": High weights in the center (where the vertical line is)\n",
        "- Digit \"0\": High weights forming a circle/oval\n",
        "- Digit \"8\": High weights forming two loops\n",
        "\n",
        "---\n",
        "\n",
        "### Visualizing Learned Features from Logistic Regression\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IjWOWeiuL1XD"
      },
      "outputs": [],
      "source": [
        "# Extract learned weights from Logistic Regression\n",
        "# Shape: (10 classes, 784 features)\n",
        "coefficients = final_logreg.coef_\n",
        "\n",
        "print(\"=\" * 70)\n",
        "print(\"LEARNED FEATURE WEIGHTS (PIXEL IMPORTANCE)\")\n",
        "print(\"=\" * 70)\n",
        "print(f\"Coefficient matrix shape: {coefficients.shape}\")\n",
        "print(f\"  {coefficients.shape[0]} classes (digits 0-9)\")\n",
        "print(f\"  {coefficients.shape[1]} features (28Ã—28 pixels)\")\n",
        "print(\"=\" * 70)\n",
        "\n",
        "# Visualize the learned weights for each digit class\n",
        "fig, axes = plt.subplots(2, 5, figsize=(15, 7))\n",
        "axes = axes.ravel()\n",
        "\n",
        "for digit in range(10):\n",
        "    # Get weights for this digit and reshape to 28Ã—28 image\n",
        "    weights = coefficients[digit].reshape(28, 28)\n",
        "\n",
        "    ax = axes[digit]\n",
        "    # Use RdBu colormap: red = negative weights, blue = positive weights\n",
        "    im = ax.imshow(weights, cmap=\"RdBu\", interpolation=\"nearest\")\n",
        "    ax.set_title(f\"Digit {digit}\\nWeights\", fontweight=\"bold\", fontsize=12)\n",
        "    ax.axis(\"off\")\n",
        "\n",
        "    # Add colorbar for reference\n",
        "    if digit == 4:  # Add colorbar to middle plot\n",
        "        plt.colorbar(im, ax=ax, fraction=0.046, pad=0.04)\n",
        "\n",
        "plt.suptitle(\n",
        "    \"Learned Pixel Weights for Each Digit Class\\n(Blue = positive weight, Red = negative weight)\",\n",
        "    fontsize=14,\n",
        "    fontweight=\"bold\",\n",
        ")\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "print(\"\\nInterpretation:\")\n",
        "print(\"   â€¢ Blue regions: Pixels that, when dark, increase probability of this digit\")\n",
        "print(\"   â€¢ Red regions: Pixels that, when dark, decrease probability of this digit\")\n",
        "print(\"   â€¢ You can see the 'template' each digit class learned!\")\n",
        "print(\"   â€¢ For example, digit '1' has strong weights in the center vertical line\")\n",
        "print(\"   â€¢ Digit '0' has strong weights forming a circular pattern\")\n",
        "print(\"   â€¢ This visualization shows what the model 'looks for' in each digit\")\n",
        "\n",
        "# Compare with actual sample digits\n",
        "print(\"\\n\" + \"=\" * 70)\n",
        "print(\"COMPARISON: LEARNED WEIGHTS vs ACTUAL SAMPLES\")\n",
        "print(\"=\" * 70)\n",
        "\n",
        "fig, axes = plt.subplots(2, 10, figsize=(15, 4))\n",
        "\n",
        "for digit in range(10):\n",
        "    # Top row: Learned weights\n",
        "    weights = coefficients[digit].reshape(28, 28)\n",
        "    axes[0, digit].imshow(weights, cmap=\"RdBu\", interpolation=\"nearest\")\n",
        "    axes[0, digit].set_title(f\"Digit {digit}\\nWeights\", fontsize=9)\n",
        "    axes[0, digit].axis(\"off\")\n",
        "\n",
        "    # Bottom row: Actual sample\n",
        "    idx = np.where(y_mnist_test == digit)[0][0]\n",
        "    sample = X_mnist[60000 + idx].reshape(28, 28)  # Get from test set\n",
        "    axes[1, digit].imshow(sample, cmap=\"gray\", interpolation=\"nearest\")\n",
        "    axes[1, digit].set_title(f\"Sample\", fontsize=9)\n",
        "    axes[1, digit].axis(\"off\")\n",
        "\n",
        "plt.suptitle(\n",
        "    \"Top: What the Model Learned  |  Bottom: Actual Examples\",\n",
        "    fontsize=14,\n",
        "    fontweight=\"bold\",\n",
        ")\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FsCYwxz_L1XD"
      },
      "source": [
        "---\n",
        "\n",
        "# Part 5: Summary and Conclusions\n",
        "\n",
        "## What You've Learned Today\n",
        "\n",
        "Congratulations! You've completed a comprehensive journey through machine learning fundamentals!\n",
        "\n",
        "### Key Takeaways:\n",
        "\n",
        "1. **Regression vs Classification**\n",
        "   - Regression: Predict continuous values (numbers)\n",
        "   - Classification: Predict categories/classes\n",
        "\n",
        "2. **Train/Test Split is Critical**\n",
        "   - Always evaluate on unseen data\n",
        "   - Prevents overfitting and gives true performance estimates\n",
        "   - Standard practice: 70-80% train, 20-30% test\n",
        "\n",
        "3. **Linear Models are Limited**\n",
        "   - Linear Regression, Perceptron, and Logistic Regression can only learn **straight line** boundaries\n",
        "   - They work great when data is linearly separable\n",
        "   - They **fail** when data requires curved boundaries\n",
        "\n",
        "4. **Neural Networks are Powerful**\n",
        "   - MLPs have hidden layers with non-linear activations (like ReLU)\n",
        "   - They can learn **complex, curved** decision boundaries\n",
        "   - Architecture matters: choose the right size for your problem\n",
        "\n",
        "5. **Real-World Considerations**\n",
        "   - Feature scaling is essential for neural networks\n",
        "   - Simple models can outperform complex ones on small/linear datasets\n",
        "   - Start simple, increase complexity only when needed\n",
        "\n",
        "6. **Evaluation Goes Beyond Accuracy**\n",
        "   - Confusion matrix shows where mistakes occur\n",
        "   - Precision: \"When I predict positive, how often am I right?\"\n",
        "   - Recall: \"Of all actual positives, how many did I find?\"\n",
        "   - F1-Score: Balance between precision and recall\n",
        "   - Choose metrics based on problem requirements\n",
        "\n",
        "7. **The Evolution**\n",
        "   ```\n",
        "   Perceptron (1958) â†’ Logistic Regression â†’ Multi-Layer Perceptron â†’ Deep Learning (2010s)\n",
        "   ```\n",
        "\n",
        "---\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hfaRPG8iL1XD"
      },
      "source": [
        "## Complete the Summary Table\n",
        "\n",
        "Based on what you've learned, complete this summary table:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nU0bDm4WL1XD"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Summary table\n",
        "summary_data = {\n",
        "    \"Model\": [\"Linear Regression\", \"Perceptron\", \"Logistic Regression\", \"MLP\"],\n",
        "    \"Model Type\": [\"Linear\", \"Linear\", \"Linear\", \"Non-Linear\"],\n",
        "    \"Problem Type\": [\n",
        "        \"Regression\",\n",
        "        \"Classification\",\n",
        "        \"Classification\",\n",
        "        \"Classification\",\n",
        "    ],\n",
        "    \"Boundary Shape\": [\n",
        "        \"Line (best fit)\",\n",
        "        \"Line (separates)\",\n",
        "        \"Line (separates)\",\n",
        "        \"Complex/Curved\",\n",
        "    ],\n",
        "    \"Can Handle Non-Linear Data\": [\"âŒ\", \"âŒ\", \"âŒ\", \"âŒ\"],  # use \"âœ…\" or \"âŒ\"\n",
        "    \"Outputs Probabilities\": [\"âŒ\", \"âŒ\", \"âŒ\", \"âŒ\"],  # use \"âœ…\" or \"âŒ\"\n",
        "}\n",
        "\n",
        "df_summary = pd.DataFrame(summary_data)\n",
        "print(\"\\n\" + \"=\" * 100)\n",
        "print(\"MODEL SUMMARY TABLE\")\n",
        "print(\"=\" * 100)\n",
        "print(df_summary.to_string(index=False))\n",
        "print(\"=\" * 100)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PopmsW1pL1XD"
      },
      "source": [
        "## Final Exercise: Reflection Questions\n",
        "\n",
        "Think about and discuss with your classmates:\n",
        "\n",
        "1. **Why did we start with Linear Regression instead of jumping straight to MLPs?**\n",
        "\n",
        "2. **When would you still use Logistic Regression instead of an MLP?**\n",
        "\n",
        "3. **What makes an MLP \"non-linear\"?**\n",
        "\n",
        "4. **If one hidden layer is good, are 100 hidden layers better?**\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h80sIQdpL1XD"
      },
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "ML_cours",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.11"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}